---
title: "Tipología y ciclo de vida de los datos: Práctica 2: Limpieza y validación de los datos"
author: "Autores: Youness El Guennouni y Mario Gutiérrez Calvo de Mora"
date: "Mayo 2019"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 4
  includes:
      in_header: PEC-header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libraries, include=FALSE}
library(knitr)
library(VIM)
library(psych)
library(ggplot2)
library(dplyr)
library(nortest)
```

******
# Introducción
******

trabajaremos con el juego de datos "Titanic" que recoge datos sobre el famoso crucero y sobre el que es fácil realizar tareas de clasificación predictiva sobre la variable "Survived".

Las actividades que llevaremos a cabo en esta práctica suelen enmarcarse en las fases iniciales de un proyecto de minería de datos y consisten en la selección de caraterásticas o variables y la preparación del juego de datos para posteriormente ser consumido por un algoritmo. 

Primeramente realizaremos el estudio de las variables de un juego de datos, es decir, haremos un trabajo descriptivo del mismo. Y de forma posterior, realizaremos el estudio de algoritmos predictivos y las conclusiones que se pueden extraer del estudio. 

Siguiendo las principales etapas de un proyecto analático, las diferentes tareas a realizar (y justificar) son las siguientes:

1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?
2. Integración y selección de los datos de interés a analizar.
3. Limpieza de los datos.
3.1. ¿Los datos contienen ceros o elementos vacáos? ¿Cómo gestionarías cada uno de estos casos?
3.2. Identificación y tratamiento de valores extremos.
4. Análisis de los datos.
4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).
4.2. Comprobación de la normalidad y homogeneidad de la varianza.
4.3. Aplicación de pruebas estadásticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.
5. Representación de los resultados a partir de tablas y gráficas.
6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?
7. Código: Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la limpieza, análisis y representación de los datos. Si lo preferás, también podéis trabajar en Python.


******
# Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?
******

El conjunto de datos objeto de análisis se ha obtenido a partir de este enlace en Kaggle y
está constituido por 12 caracterásticas (columnas) que presentan a los 891 pasajeros (filas o registros).
Entre los campos de este conjunto de datos, encontramos los siguientes:  

  * **PassengerId**: identificador unico del pasajero.  
  * **Survived**: Si el pasajero ha sobrevivido (1) o no (0)  
  * **Pclass**: En que clase viajaba  
  * **Name**: Nombre de pasajero  
  * **Sex**: genéro de pasajero  
  * **SibSp**: Numero de hermanos / cónyuges a bordo  
  * **Parch**: Numero de padres / hijos a bordo  
  * **Ticket**: Numero de ticket  
  * **Fare**: tárifa del viaje  
  * **Cabin**: Cabina  
  * **Embarked**: El puerto desde el cual ha embarcado el pasajero (C- Cherbourg, S - Southampton, Q - Queenstown)

Es importante saber a que preguntas debemos de responder para definir un objetivo claro y no desviarnos de ello. En nuestro caso el problema que debemos de solventar será ¿Que factores influyen directamente o indirectamente en la superviviencia o no de un pasajero? Además, se podrá proceder a crear modelos de regresión que permitan predecir la supervivencia o no de un pasajero en función de sus caráctiristas y contrastes de hipótesis que ayuden a identificar propiedades interesantes en las muestras que puedan ser inferidas con respecto a la población.

# Integración y selección de los datos de interés a analizar

Desde el análisis de los datos podemos descartar algunos factores desde el inicio como el numero de ticket, tarifa o nombre de pasajero. Otro dato que decidimos no tenerle en cuenta es la cabina ya que más de 70% vienen vacios.

## Lectura de ficheros
Cargar a los archivos `train.csv` y`test.csv`. Una vez cargado el archivo, valida que los tipos de datos
son los correctos. Si no es asá, conviertelos al tipo oportuno.

* Archivo de datos (`train.csv`)  
```{r lectura, echo=TRUE, eval=TRUE}
 train <- read.csv( "./data/train.csv")
 head(train)
 
 sapply( train, class)
```

* Archivo de los tests (`test.csv`)
```{r lectura2, echo=TRUE, eval=TRUE}
 test <- read.csv( "./data/test.csv")
 head(test)
 
 sapply( test, class)
```

## Borrar a las columnas innecesarias
```{r echo=TRUE, message=FALSE, warning=FALSE}
train <- select(train, -Name, -Ticket )
test  <- select(test, -Name, -Ticket )
head (train)
```

# Limpieza de datos
En esta sección vamos a llevar a cabo el proceso de limpieza de datos que consiste en:

## Los datos contienen ceros o elementos vacíos
A continuación vamos a detectar a los valores vacios y nulos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estadísticas de valores vacíos
colSums(is.na(train))
colSums(train=="")

```

Llegados a este punto debemos decidir cómo manejar estos registros que contienen valores desconocidos para algun campo. Una opción podrá ser eliminar esos registros que incluyen este tipo de valores, pero ello supondría desaprovechar información.  
Como alternativa, se empleará un método de imputación de valores basado en la similitud o diferencia entre los registros: la imputación basada en k vecinos más próximos.  La elección de esta alternativa se realiza bajo la hipótesis de que nuestros registros guardan cierta relación. No obstante, es mejor trabajar con datos aproximados que con los propios elementos vacíos, ya que obtendremos análisis con menor margen de error.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Para los valores perdidos procedemos con aplicar la distancia de Gower
#train$Age <- kNN(train)$Age
#train$Embarked <- kNN(train)$Embarked
#train$Parch <- kNN(train)$Parch
#train$SibSp <- kNN(train)$SibSp
#train$Survived <- kNN(train)$Survived
train <- kNN(train)

#Rempazar la edad por la media
train$Age[is.na(train$Age)] <- winsor.mean(train$Age,trim=0.05)

# Tomamos valor "C" para los valores vacáos de la variable "Embarked"
train$Embarked[train$Embarked==""]="C"

sapply(train, function(x) sum(is.na(x)))


```


## Identificación y tratamiento de valores extremos

* Cuadro de las estimaciónes no robustas y robustas.

En el siguiente cuadro se van a mostrar a las estimaciones no robustas y robustas por un posible uso a la hora de remplazar a los valores perdidos o a los extremos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
age_s<-summary(train$Age)
pclass_s<-summary(train$Pclass)
sibSp_s<-summary(train$SibSp)
parch_s<-summary(train$Parch)

table_s <- suppressWarnings(rbind(age_s,pclass_s,sibSp_s,parch_s))
age_r <- c(sd(train$Age), winsor.mean(train$Age,trim=0.05), IQR(train$Age))
pclass_r <- c(sd(train$Pclass), "NA", IQR(train$Pclass))
sibSp_r <- c(sd(train$SibSp), winsor.mean(train$SibSp,trim=0.05), IQR(train$SibSp))
parch_r <- c(sd(train$Parch), winsor.mean(train$Parch,trim=0.05), IQR(train$Parch))

table_r <- rbind(age_r,pclass_r,sibSp_r, parch_r)
table_res <- cbind(table_s, table_r)
colnames( table_res) <- c("Min", "1st Qu", "Median", "Mean", "3rd Qu", "Max", "SD", "WINSOR", "IQR")
kable(table_res)
```

* Detactamos a los valores extremos

Los valores extremos o outliers son aquellos que parecen no ser congruentes sin los comparamos con el resto de los datos. Para identificarlos, podemos hacer uso de dos vías: (1) representar un diagrama de caja por cada variable y ver qué valores distan mucho del rango intercuartílico(la caja) o (2) utilizar la función boxplots.stats() de R, la cual se emplea a continuación.
Así, se mostrarán sólo los valores atípicos para aquellas variables que los contienen:


```{r echo=TRUE, message=FALSE, warning=FALSE}
#Los valores atápicos Age
boxplot.stats(train$Age)$out
#Los valores atápicos SibSp.
boxplot.stats(train$SibSp)$out
#Los valores atápicos Parch.
boxplot.stats(train$Parch)$out
```

No obstante, si revisamos los anteriores datos para varios pasajeros escogido aleatoriamente de
esta web, comprobamos que son valores que perfectamente pueden darse. Es por ello que el manejo de
estos valores extremos consistirá en simplemente dejarlos como actualmente están recogidos.


# Análisis de los datos

Se representan gráficamente las variables del conjunto de datos para poder visualizar la distribución de valores de las variables. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
Embarkedsum <- summarize( group_by(train, Embarked), n=length(Embarked))
ggplot( Embarkedsum, aes(x="", y=n, fill=Embarked)) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start=0) + ggtitle("Embarked")
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
Survivedsum <- summarize( group_by(train, Survived), n=length(Survived))
ggplot( Survivedsum, aes(x="", y=n, fill=Survived)) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start=0) + ggtitle("Survived")
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
Sexsum <- summarize( group_by(train, Sex), n=length(Sex))
ggplot( Sexsum, aes(x="", y=n, fill=Sex)) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start=0) + ggtitle("Sex")
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
Pclasssum <- summarize( group_by(train, Pclass), n=length(Pclass))
ggplot( Pclasssum, aes(x="", y=n, fill=Pclass)) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start=0) + ggtitle("Pclass")
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
Agesum <- summarize( group_by(train, Age), n=length(Age))
ggplot(Agesum, aes(x="", y=n, fill=Age))+
geom_bar(width = 1, stat = "identity") + ggtitle("Age")+
coord_polar("y", start=0)
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
par(mfrow=c(1,3))
#boxplot(train$Survived, main="Survived")
boxplot(train$Age, main="Age")
boxplot(train$Parch, main="Parch")
boxplot(train$SibSp, main="SibSp")
#boxplot(train$Pclass, main="Pclass")
par(mfrow=c(1,1))
```


## Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar)  
A continuación, se seleccionan los grupos dentro de nuestro conjunto de datos que pueden resultar interesantes para analizar y/o comparar. No obstante, como se verá en el apartado consistente en la realización de pruebas estadásticas, no todos se utilizarán.
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Agrupación por genero
train.female <- train[train$Sex == "female",]
train.male <- train[train$Sex == "male",]

# Agrupación por puerta de embarque
train.c <- train[train$Embarked == "C",]
train.s <- train[train$Embarked == "S",]
train.q <- train[train$Embarked == "Q",]

# Agrupación por Parch
train.parch.cero <- train[train$Parch == "0",]
train.parch.mayor <- train[train$Parch > "0",]

# Agrupación por Parch
train.sibSp.cero <- train[train$SibSp == "0",]
train.sibSp.mayor <- train[train$SibSp > "0",]

#Usar el termino de tamaño de la familia sumando parch y SibSp
train$FamilySize <- train$SibSp + train$Parch +1;


```

## Comprobación de la normalidad y homogeneidad de la varianza
Para la comprobación de que los valores que toman nuestras variables cuantitativas provienen
de una población distribuida normalmente, utilizaremos la prueba de normalidad de Anderson-
Darling.

Asi, se comprueba que para que cada prueba se obtiene un p-valor superior al nivel de
significación prefijado $\alpha$ = 0, 05. Si esto se cumple, entonces se considera que variable en
cuestión sigue una distribución normal.

```{r echo=TRUE, message=FALSE, warning=FALSE}
alpha = 0.05
col.names = colnames(train)
for (i in 1:ncol(train)) {
  if (i == 1) cat("Variables que no siguen una distribución normal:\n")
  if (is.integer(train[,i]) | is.numeric(train[,i])) {
    p_val = ad.test(train[,i])$p.value
    if (p_val < alpha) {
      cat(col.names[i])
      # Format output
      if (i < ncol(train) - 1) cat(", ")
      if (i %% 3 == 0) cat("\n")
    }
  }
}
```


## Aplicación de pruebas estadásticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes

Vamos a estudiar la homogeneidad de varianzas mediante la aplicación de un test de Fligner-Killeen. En este caso, estudiaremos esta homogeneidad en cuanto a la cabina del pasajero. En el siguiente test, la hipótesis nula consiste en que ambas varianzas son iguales.
```{r echo=TRUE, message=FALSE, warning=FALSE}
#fligner.test(apply(Survived, 2, function(x) as.numeric(as.character(x))) ~ Sex, data = train)
fligner.test(Survived ~ Cabin , data = train)
#fligner.test(train)
```

Puesto que obtenemos un p-valor superior a 0,05, aceptamos la hipótesis de que las varianzas de ambas muestras son homogéneas. Detectamos la cabina de pasajero no es un factor que ha influido en la supervivencia de los pasajeros.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#fligner.test(Survived ~ Embarked, data = train)
```

Procedemos a realizar un análisis de correlación entre las distintas variables para determinar cuáles de ellas ejercen una mayor influencia sobre el precio final del veháculo. Para ello, se utilizará el coeficiente de correlación de Spearman, puesto que hemos visto que tenemos datos que no siguen una distribución normal.
```{r echo=TRUE, message=FALSE, warning=FALSE}
corr_matrix <- matrix(nc = 2, nr = 0)
colnames(corr_matrix) <- c("estimate", "p-value")
# Calcular el coeficiente de correlación para cada variable cuantitativa
# con respecto al campo "Survived"
for (i in 3:(ncol(train) - 1)) {
  if (is.integer(train[,i]) | is.numeric(train[,i])) {
    spearman_test = cor.test(train[,i], train[,2], method = "spearman")
    corr_coef = spearman_test$estimate
    p_val = spearman_test$p.value
    #z Add row to matrix
    pair = matrix(ncol = 2, nrow = 1)
    pair[1][1] = corr_coef
    pair[2][1] = p_val
    corr_matrix <- rbind(corr_matrix, pair)
    rownames(corr_matrix)[nrow(corr_matrix)] <- colnames(train)[i]
  }
}
print(corr_matrix)

is_number <- sapply(train,is.numeric)
correlacion <-cor(train[,is_number])
correlacion
```

Así, identificamos cuáles son las variables más correlacionadas con el precio en función de su proximidad con los valores -1 y +1. Teniendo esto en cuenta, queda patente cómo la variable más relevante en la supervivencia es la clase donde viajaba el pasajero (Pclass).

Nota. Para cada coeficiente de correlación se muestra también su p-valor asociado, puesto
que éste puede dar información acerca del peso estadístico de la correlación obtenida.

##¿Ha influido el genero en la supervivencia de los pasajeros?
Nos preguntamos si existen diferencias significativas en la supervivencia de los hombres en relación a las mujeres. Para responder a esta pregunta, siga los pasos que se detallan a continuación.

el cotraste de hipótesis de dos muestras sobre sobre la diferencia de medidas, el cual es unilateral atendiendo a la formulación de la hipótesis alternativa:

$H_0: \mu_{1} - \mu_{2} = 0$ 

$H_1: \mu_{1} - \mu_{2} < 0$ 

donde μ1 es la media de la población de la que se extrae la primera muestra y μ2 es la media
de la población de la que extrae la segunda. Así, tomaremos $\alpha$ = 0, 05.

### Test de Shapiro
```{r echo=TRUE, message=FALSE, warning=FALSE}
#Test d'igualtat de variances
#H0: F (rati de variàncies) = 1
#H0 : F diferent d'1
shapiro.test(train$Survived[train$Sex=="male"])
#var.test(train$Survived[train$Sex=="male"], train$Survived[train$sex=="female"], alternative = "two.sided")
```
Según el test Shapiro Wilk, podemos asumir normalidad. Por lo tanto, aplicamos un test de dos muestras independientes para la diferencia de las medias. Aplicamos el caso de datos normales, con varianza desconocida. El test es bilateral (dos colas).
```{r echo=TRUE, message=FALSE, warning=FALSE}
#Test d'igualtat de variances
#H0: F (rati de variàncies) = 1
#H0 : F diferent d'1
var.test(train$Survived[train$Sex=="male"], train$Survived[train$Sex=="female"], alternative = "two.sided")
```
El resultado del test F es que podemos asumir igualdad de varianzas. Por lo tanto, aplicamos test t de dos muestras independientes para la diferencia de medias, varianzas desconocidas e iguales. El test es bilateral.

### Calculo manual

```{r echo=TRUE, message=FALSE, warning=FALSE}
nF<-nrow( train.male)
meanF<-mean(train.male$Survived)
sdF <- sd( train.male$Survived)
#
nM<-nrow( train.female )
meanM<-mean(train.female$Survived)
sdM <- sd( train.female$Survived)
#
s <-sqrt( ((nF-1)*sdF^2 + (nM-1)*sdM^2 )/(nF+nM-2) )
Sb <- s*sqrt(1/nF + 1/nM)
t <- (meanF-meanM)/ Sb
t
alfa <- (1-0.95)
tcritical <- qt( alfa/2, df=nF+nM-2, lower.tail=FALSE )
#two-sided
pvalue<-pt( abs(t), df=nF+nM-2, lower.tail=FALSE )*2
#Print info
info<-data.frame(nF,meanF,sdF,nM,meanM,sdM,t,tcritical,pvalue)

info

```
como el valor de p es `r info$pvalue` < 0.05 podemos rechazar la hipótesis nula. La respuesta seria que si ha influido el genero.

### Aplicando el test no parametrico de Mann-Whitney
```{r echo=TRUE, message=FALSE, warning=FALSE}
t.test(train.male$Survived, train.female$Survived, alternative = "less")
```
Puesto que obtenemos un p-valor menor que el valor de significación fijado, rechazamos la hipótesis nula. Por tanto, podemos concluir que, efectivamente, el genero de un pasajero ha influido en la supervivencia.


##Modelo de regresión lineal
Tal y como se planteó en los objetivos de la actividad, resultará de mucho interés poder realizar predicciones sobre la supervivencia de un pasajero dadas sus características. Así, se calculará un modelo de regresión lineal utilizando regresores tanto cuantitativos como cualitativos con el que poder realizar las predicciones de la supervivencia o no.

Para obtener un modelo de regresión lineal considerablemente eficiente, lo que haremos será obtener varios modelos de regresión utilizando las variables que estén más correladas con respecto al precio, según la tabla obtenido en el apartado 5.3. Así, de entre todos los modelos que tengamos, escogeremos el mejor

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Regresores cuantitativos con mayor coeficiente
# de correlación con respecto a la supervivencia
legth = train$length
width = train$width
train.Age = train$Age
train.sibSp = train$SibSp
train.Parch = train$Parch
train.FamilySize = train$FamilySize
# Regresores cualitativos
train.Sex = train$Sex
train.Pclass = train$Pclass
train.Embarked = train$Embarked
train.Fare = train$Fare
#train.EmbarkedR=relevel(train$Embarked, ref = 'C')
#train$educ_levelR=relevel(train$educ_level, ref = 'N')
# Variable a predecir
Survived = train$Survived
# Generación de varios modelos
modelo1 <- lm(Survived ~ train.Age +train.Fare + train.Sex + train.Embarked + train.sibSp + train.Parch + train.Pclass, data = train)
#modelo1 <- lm(Survived ~ train.Age + train.Pclass, data = train)
modelo2 <- lm(Survived ~ train.sibSp + train.Fare + train.Sex + train.Embarked + train.Parch + train.Pclass, data = train)
modelo3 <- lm(Survived ~ train.Age + train.Fare + train.Sex + train.Embarked + train.Parch + train.Pclass, data = train)
modelo4 <- lm(Survived ~ train.Age + train.Fare + train.Sex + train.Embarked + train.sibSp + train.Pclass, data = train)
modelo5 <- lm(Survived ~ train.Age + train.Fare + train.Sex + train.Embarked + train.sibSp + train.Parch , data = train)
modelo6 <- lm(Survived ~ train.Age + train.Fare + train.Sex + train.Embarked + train.FamilySize + train.Pclass, data = train)
modelo7 <- lm(Survived ~ train.Sex + train.Fare + train.Embarked + train.FamilySize + train.Pclass, data = train)

```
Para los anteriores modelos de regresión lineal múltiple obtenidos, podemos utilizar el coeficiente de determinación para medir la bondad de los ajustes y quedarnos con aquel modelo que mejor coeficiente presente.
```{r echo=TRUE, message=FALSE, warning=FALSE}
tabla.coeficientes <- matrix(c(1, summary(modelo1)$r.squared,
                              2, summary(modelo2)$r.squared,
                              3, summary(modelo3)$r.squared,
                              4, summary(modelo4)$r.squared,
                              5, summary(modelo5)$r.squared,
                              6, summary(modelo6)$r.squared,
                              7, summary(modelo7)$r.squared),
                              ncol = 2, byrow = TRUE)
colnames(tabla.coeficientes) <- c("Modelo", "R^2")
tabla.coeficientes
```


##Modelo de regresión logística

Trabajaremos con la variable binaria (Survived) que indica la condición de sobrevivir o no.
Estimar el modelo de regresión logística donde la variable dependiente es "Survived" y las explicativas son la capacidad pulmonar Fare, Age y Sex. 

Evaluar si alguno de los regresores tiene influencia significativa  (p-valor del contraste individual inferior al 5%).

```{r echo=TRUE, message=FALSE, warning=FALSE}

Model.2.1=glm(Survived~Fare + Age + Sex, family=binomial, data=train)
summary(Model.2.1)

sel <- which(summary(Model.2.1)$coefficients[-1,4] < 0.05)
sel <- sel + 1
```

Ha sido algo significativo el test parcial sobre la variable Sex(Male). siendo la estimación de su coeficiente -2.4017.

Se podría decir que un individuo con más posibilidades de ser mujer, tiene mayor probabilidad de sobrevivir, ya que el signo negativo en Sex(Male) es un factor de "protección" ante el riesgo de sobrevivir. entonces cuantas menos posibilidades de ser hombre, mayor probabilidad de sobrevivir.


## Creación del modelo, calidad del modelo y extracción de reglas en clasificación arboles de decisión

Nuestro objetivo es crear un árbol de decisión que permita analizar qué tipo de pasajero del Titanic tenía probabilidades de sobrevivir o no. Por lo tanto, la variable por la que clasificaremos es el campo de si el pasajero sobrevivió o no. De todas maneras, al imprimir las primeras y últimas 10 filas nos damos cuenta de que los datos están ordenados, por lo tanto, nos interesará "desordenarlos". Guardaremos los datos con el nuevo nombre como "train_random".
Vamos a usar solo el juego de datos "train" dado que es el único que contiene la variable Survived.

```{r}
#Mediante head() obtenemos las primeras filas de nuestro dataframe
head(train,10)
#Mediante head() obtenemos las últimas filas de nuestro dataframe
tail(train,10)
set.seed(666)
#Queremos "desordenar" los datos
train_random <- train[sample(nrow(train)),]
```

Vamos a separar las columnas que consideramos más representaticas y la variable por la que clasificaremos que será si ha sobrevivido o no. 

```{r}
#la variable por la que clasificaremos es el campo de si el pasajero sobrevivió o no, 
#que está en la cuarta columna.

train_random$Pclass<-as.factor(train_random$Pclass)
train_random$Survived<-as.factor(train_random$Survived)

set.seed(666)
trainy <-train_random[,c(2)] #SURVIVED
trainX <- train_random[,c(3,4,9,10)] #Resto de variables

levels(trainX$Cabin)[1] = "missing"
levels(trainX$Embarked)[1] = "missing"

```

Ejecutamos el modelo.

```{r}
#Se crea el arbol de decision usando los datos de Entrenamiento.
model_class <- C50::C5.0(trainX, trainy, rules=TRUE )
summary(model_class)
```

Errors muestra el número y porcentaje de casos mal clasificados, erróneamente 168 de los 891 casos dados, una tasa de error del 18.9%.

A partir del árbol de decisión que hemos modelado, se pueden extraer las siguientes reglas de decisión (gracias a rules=TRUE podemos imprimir las reglas directamente):

SEX = "male" → Muere Validez: 81%

CLASS = "3a" → Muere Validez: 75,7%

CLASS = (1,2) y SEX = "female" → Sobrevive Validez: 94,2%

CLASS (C,Q) y SEX = "female" → Sobrevive Validez: 83,2%

Por tanto podemos concluir que el conocimiento extraido se resume en "las mujeres que viajaban en 1a y 2a clase sobreviven". También que "Las mujeres que embarcaron en Cherbourg o en Queenstown sobreviven", esta última con un porcentaje de predicción menor.

Visualizaremos el árbol en el siguiente apartado.



# Representación de los resultados a partir de tablas y gráficas

Generación del árbol.

```{r}
model <- C50::C5.0(trainX, trainy)
plot(model)
```

Discretizamos cuando tiene sentido y en función de cada variable.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# ¿Para qué variables tendría sentido un proceso de discretización?
apply(train,2, function(x) length(unique(x)))

# Discretizamos las variables con pocas clases
cols<-c("Survived","Pclass","Sex","Embarked")
for (i in cols){
  train[,i] <- as.factor(train[,i])
}

# Después de los cambios, analizamos la nueva estructura del juego de datos
str(train)
```

Obtenemos una matriz de porcentages de frecuencia.  
Vemos, por ejemplo que la probabilidad de sobrebivir si se embarcó en "C" es de un 55,88%

```{r echo=TRUE, message=FALSE, warning=FALSE}
filas=dim(train)[1]
t<-table(train[1:filas,]$Embarked,train[1:filas,]$Survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```

Veamos ahora como en un mismo gráfico de frecuencias podemos trabajar con 3 variables: Embarked, Survived y Pclass.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Now, let's devide the graph of Embarked by Pclass:
ggplot(data = train[1:filas,],aes(x=Embarked,fill=Survived))+geom_bar(position="fill")+facet_wrap(~Pclass)
```

Comparemos ahora dos gráficos de frecuencias: Survived-SibSp y Survived-Parch

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survivial como función de SibSp y Parch
ggplot(data = train[1:filas,],aes(x=SibSp,fill=Survived))+geom_bar()
ggplot(data = train[1:filas,],aes(x=Parch,fill=Survived))+geom_bar()
# Vemos como las forma de estos dos gráficos es similar. Este hecho nos puede indicar presencia de correlaciones altas.
```

Veamos un ejemplo de construcción de una variable nueva: Tamaño de familia

```{r echo=TRUE, message=FALSE, warning=FALSE}
train1<-train[1:filas,]
ggplot(data = train1[!is.na(train[1:filas,]$FamilySize),],aes(x=FamilySize,fill=Survived))+geom_histogram(binwidth =1,position="fill")+ylab("Frecuencia")

# Observamos como familias de entre 2 y 6 miembros tienen más del 50% de posibilidades de supervivencia.  
```

Veamos ahora dos gráficos que nos compara los atributos Age y Survived.  
Observamos como el parámetro position="fill" nos da la proporción acumulada de un atributo dentro de otro

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survival como función de age:
ggplot(data = train1[!(is.na(train[1:filas,]$Age)),],aes(x=Age,fill=Survived))+geom_histogram(binwidth =3)
ggplot(data = train1[!is.na(train[1:filas,]$Age),],aes(x=Age,fill=Survived))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")
```


# Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

Aunque consideramos que los datos no eran suficientes en volumen para extraer ideas más contundentes, se han podido extraer ideas como:

1. Las mujeres que viajaban en primera y segunda clase prácticamente sobrevivieron. 
2. Que murieron más hombres que mujeres.
3. Que murió mucha gente que viajaba en 3a clase.

##Calidad del ajuste
Calcular la matriz de confusión del mejor modelo del apartado 2.3 suponiendo un umbral de discriminación del 75 %. Observad cuantos falsos negativos hay e interpretar qué es un falso negativo en este contexto. Hacer lo mismo con los falsos positivos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
train$prob_Survived= predict(modelo6, train, type="response")
train$pred_Survived <- ifelse(train$prob_Survived > 0.75,1,0)
table(train$Survived, train$pred_Survived)
```

Un falso negativo en este concepto corresponde a los viajeros que se han predecido como no sobrevivientes cuando realmente sí han sobrevivido. Tenemos `r table(train$Survived, train$pred_Survived)[2][1]` falsos negativos. 

Un falso positivo en este concepto corresponde a los viajeros que se han predicho como sobrevivientes y no lo han sido realmente. Tenemos `r table(train$Survived, train$pred_Survived)[3]` falsos positivos. 


